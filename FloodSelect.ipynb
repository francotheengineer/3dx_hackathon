{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact_manual\n",
    "import cv2\n",
    "import keras\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('floodmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IMG_DIR = ''\n",
    "image_name = 'demoTALWOOD.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FLOOD_DIR = 'flood_images/DP_TALWOOD_AERIALPHOTO_2011_50CM/'\n",
    "NON_FLOOD_DIR ='non_flood_images/DP_TALWOOD_AERIALPHOTO_2011_50CM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(IMG_DIR, image_name))\n",
    "full_map = cv2.imread('./DP_TALWOOD_AERIALPHOTO_2011_50CM.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img,  cv2.COLOR_BGR2RGB)\n",
    "full_map = cv2.cvtColor(full_map,  cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.resize(img, (5000,5000)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch_width = 512\n",
    "w, h = img.shape[:2]\n",
    "num_wide = w//patch_width\n",
    "num_high =  h//patch_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "global n\n",
    "n = 22\n",
    "# n = 268\n",
    "\n",
    "\n",
    "if(n<0):\n",
    "    n=n+1\n",
    "print(n)\n",
    "j = n % num_wide\n",
    "i = n//num_wide\n",
    "\n",
    "patch = img[i*patch_width:(i+1)*patch_width, j*patch_width:(j+1)*patch_width]\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))   \n",
    "# we won't need to do this later\n",
    "# smaller_map = img[i*patch_width:(i+1)*patch_width, j*patch_width:(j+1)*patch_width]\n",
    "ax1.imshow(patch)\n",
    "ax2.imshow(full_map)\n",
    "plt.show()\n",
    "\n",
    "@interact_manual(is_flood=widgets.IntSlider(min=-1,max=1,step=1,value=0))\n",
    "def selectImage(is_flood):\n",
    "    global n\n",
    "    j = n % num_wide\n",
    "    i = n//num_wide\n",
    "    patch = img[i*patch_width:(i+1)*patch_width, j*patch_width:(j+1)*patch_width]\n",
    "    #patch= cv2.cvtColor(patch,  cv2.COLOR_RGB2BGR)\n",
    "#     if(is_flood==1):\n",
    "#         cv2.imwrite(os.path.join(FLOOD_DIR, str(n)+image_name), patch)\n",
    "#     elif(is_flood==-1):\n",
    "#         cv2.imwrite(os.path.join(NON_FLOOD_DIR, str(n)+image_name), patch)\n",
    "    n = n+1\n",
    "\n",
    "    print(n, \"currently \", n % 43, \" out of 43 across the page more or less\")\n",
    "    j = n % num_wide\n",
    "    i = n//num_wide\n",
    "\n",
    "    patch = img[i*patch_width:(i+1)*patch_width, j*patch_width:(j+1)*patch_width]\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # we won't need to do this later\n",
    "#     smaller_map()\n",
    "    \n",
    "    ax1.imshow(patch)\n",
    "    ax2.imshow(full_map)\n",
    "#     ax2.\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_images = 64\n",
    "img_with_red_box = img.copy()\n",
    "for n in range(64):\n",
    "    #clear_output()\n",
    "    j = n % num_wide\n",
    "    i = n//num_wide\n",
    "    patch = img[i*patch_width:(i+1)*patch_width, j*patch_width:(j+1)*patch_width]\n",
    "#     print(n, \"currently \", n % 43, \" out of 43 across the page more or less\")\n",
    "    patch = img[i*patch_width:(i+1)*patch_width, j*patch_width:(j+1)*patch_width]\n",
    "    patch_resized = cv2.resize(patch, (128, 128))[np.newaxis, :,:,:].astype(np.float32)/255\n",
    "    prediction = model.predict(patch_resized)\n",
    "    # Adding red box code\n",
    "    try:\n",
    "        start_x_patch = i*patch_width\n",
    "        end_x_patch = (i+1)*patch_width\n",
    "        start_y_patch = (j-1)*patch_width\n",
    "        end_y_patch = (j)*patch_width\n",
    "        sizepatch = (img_with_red_box[start_x_patch:end_x_patch, start_y_patch:end_y_patch]).shape\n",
    "        score_patch = np.ones(shape=sizepatch)*prediction\n",
    "        color_patch = np.ones(shape=sizepatch)*1\n",
    "        color_patch[:,:,1:] =0\n",
    "        #print(patch.shape, color_patch.shape, score_patch.shape)\n",
    "        img_with_red_box[start_x_patch:end_x_patch, start_y_patch:end_y_patch] = patch*(1-score_patch) + color_patch*(score_patch)\n",
    "\n",
    "\n",
    "    #     #top bottom left right\n",
    "    #     w_l = 8\n",
    "    #     img_with_red_box[start_x_patch:end_x_patch, start_y_patch-w_l:start_y_patch+w_l] = np.array([255,0,0])\n",
    "    #     img_with_red_box[start_x_patch:end_x_patch,end_y_patch-w_l:end_y_patch+w_l] = np.array([255,0,0])\n",
    "    #     img_with_red_box[start_x_patch-w_l:start_x_patch+w_l,start_y_patch:end_y_patch] = np.array([255,0,0])\n",
    "    #     img_with_red_box[end_x_patch-w_l:end_x_patch+w_l,start_y_patch:end_y_patch] = np.array([255,0,0])\n",
    "\n",
    "        # Plot the main image and the side image \n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        ax1.imshow(patch)\n",
    "        ax2.imshow(img_with_red_box)\n",
    "        #fig.canvas.draw()\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# n = 1016\n",
    "# j = n % num_wide\n",
    "# i = n//num_wide\n",
    "# patch = img[i*patch_width:(i+1)*patch_width, j*patch_width:(j+1)*patch_width]\n",
    "# patch1 = cv2.resize(patch, (128, 128))[np.newaxis, :,:,:].astype(np.float32)/255\n",
    "# plt.imshow(patch1[0])\n",
    "# plt.show()\n",
    "# model.predict(patch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 12\n",
    "\n",
    "j = n % num_wide\n",
    "i = n//num_wide\n",
    "\n",
    "img2 = img.copy()\n",
    "\n",
    "start_x_patch = i*patch_width\n",
    "end_x_patch = (i+1)*patch_width\n",
    "start_y_patch = (j-1)*patch_width\n",
    "end_y_patch = (j)*patch_width\n",
    "\n",
    "#top bottom left right\n",
    "w_l = 4\n",
    "img2[start_x_patch:end_x_patch, start_y_patch-w_l:start_y_patch+w_l] = np.array([255,0,0])\n",
    "img2[start_x_patch:end_x_patch,end_y_patch-w_l:end_y_patch+w_l] = np.array([255,0,0])\n",
    "img2[start_x_patch-w_l:start_x_patch+w_l,start_y_patch:end_y_patch] = np.array([255,0,0])\n",
    "img2[end_x_patch-w_l:end_x_patch+w_l,start_y_patch:end_y_patch] = np.array([255,0,0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# start_x = np.maximum(i*patch_width - (1*patch_width),0)\n",
    "# end_x = np.minimum(i*patch_width + (2*patch_width), num_wide*patch_width)\n",
    "# start_y = np.maximum(j*patch_width - (2*patch_width),0)\n",
    "# end_y = np.minimum(j*patch_width + (1*patch_width), num_high*patch_width)\n",
    "\n",
    "# patch = img2[start_x:end_x, start_y:end_y]\n",
    "patch = img2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(patch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this = cv2.imread(\"/home/henrye/challenge/non_flood_images/DP_TALWOOD_AERIALPHOTO_2011_50CM/320DP_TALWOOD_AERIALPHOTO_2011_50CM.jpg\")\n",
    "# this.shape\n",
    "# plt.imshow(cv2.resize(this, (5000,5000)))\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
